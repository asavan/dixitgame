class NanoNeuron {
    constructor(w, b) {
        // Нейрончику известны только эти два параметра линейной функции.
        // Значения этих параметров будут определяться нейрончиком в процессе обучения
        if (w == null || b == null || isNaN(b) || isNaN(w)) {
            throw new Error("Cannot construct undefined!");
        }
        this.w = w
        this.b = b
    }
    // Все, что умеет нейрончик, - имитировать линейную зависимость.
    // Он принимает некоторый 'x' и предсказывает 'y'. Никакой магии
    predict(x) {
        return x * this.w + this.b
    }
}

// Конвертирует градусы Цельсия в градусы Фаренгейта по формуле: f = 1.8 * c + 32.
// Мы хотим научить нейрончика имитировать эту функцию, т.е.
// научить, что W = 1.8, а B = 32 без предоставления этих значений.
// c - температура в градусах Цельсия
// f - вычисленная температура в градусах Фаренгейта
const W = 1.8
const B = 32
function celsiusToFahrenheit(c) {
    const f = c * W + B
    return f
}

// Генерирует обучающий и тестовый наборы данных с помощью функции celsiusToFahrenheit().
// Наборы состоят из пар входных значений и правильно размеченных результатов.
// В реальной жизни в большинстве случаев эти данные будут собраны, а не сгенерированы.
// Например, у нас может быть набор изображений рукописных цифр и
// набор соответствующих цифр
function generateDataSets() {
    // Генерируем ТРЕНИРОВОЧНЫЕ данные.
    // Эти данные будут использоваться для обучения модели.
    // Перед тем, как нейрончик вырастет и сможет принимать решения самостоятельно,
    // мы должны объяснить ему, что такое хорошо и что такое плохо с помощью
    // тренировочных примеров.
    // xTrain -> [0, 1, 2, ...],
    // yTrain -> [32, 33.8, 35.6, ...]
    const xTrain = []
    const yTrain = []
    for (let x = 0; x < 120; x += 1) {
        const y = celsiusToFahrenheit(x)
        xTrain.push(x)
        yTrain.push(y)
    }

    // Генерируем ТЕСТОВЫЕ данные.
    // Эти данные будут использоваться для оценки того, насколько хорошо модель работает с данными,
    // которых она не видела в процессе обучения. Здесь мы можем увидеть,
    // что наш "ребенок" вырос и может принимать решения самостоятельно.
    // xTest -> [0.5, 1.5, 2.5, ...]
    // yTest -> [32.9, 34.7, 36.5, ...]
    const xTest = []
    const yTest = []
    // Начиная с 0.5 и используя такой же шаг 1,
    // который мы использовали для тренировочного набора,
    // мы обеспечиваем уникальность данных
    for (let x = 0.5; x < 100; x += 1) {
        const y = celsiusToFahrenheit(x)
        xTest.push(x)
        yTest.push(y)
    }

    return [xTrain, yTrain, xTest, yTest]
}

// Вычисляем стоимость (ошибку) между правильным значением 'y' и
// 'prediction' (предсказанием), сделанным нейрончиком
function predictionCost(y, prediction) {
    // Это просто разница между двумя значениями.
    // Чем ближе значения друг к другу, тем меньше разница.
    // Мы используем здесь степень 2 только для того, чтобы избавиться от отрицательных чисел,
    // поэтому (1 - 2) ^ 2 = (2 - 1) ^ 2.
    // Результат делится на 2 просто для упрощения дальнейшей формулы обратного распространения (см. ниже)
    return (y - prediction) ** 2 / 2 // например -> 235.6
}

// Прямое распространение.
// Эта функция берет все примеры из тренировочных наборов xTrain и yTrain
// и вычисляет предсказания модели для каждого примера из xTrain.
// По пути она также вычисляет среднюю стоимость предсказаний
function forwardPropagation(model, xTrain, yTrain) {
    const m = xTrain.length
    const predictions = []
    let cost = 0
    for (let i = 0; i < m; i += 1) {
        const prediction = model.predict(xTrain[i])
        if (isNaN(prediction) || Math.abs(prediction) > 1000) {
            console.trace(prediction, i, xTrain[i], model)
            throw new Error(prediction)
        }
        cost += predictionCost(yTrain[i], prediction)
        predictions.push(prediction)
    }
    // Нас интересует средняя стоимость
    cost /= m
    return [predictions, cost]
}

// Обратное распространение.
// В этом месте машинное обучение выглядит как магия.
// Ключевой концепцией здесь является производная (derivative), которая показывает, какой шаг нужно предпринять, чтобы
// приблизиться к минимуму функции стоимости. Помните, нахождение минимальной функции стоимости -
// конечная цель процесса обучения. Функция стоимости выглядит следующим образом:
// (y - prediction) ^ 2 * 1/2, где prediction = x * w + b.
function backwardPropagation(predictions, xTrain, yTrain) {
    const m = xTrain.length
    // В начале мы не знаем, как менять параметры 'w' и 'b'.
    // Поэтому устанавливаем шаг изменения для каждого параметра в значение 0
    let dW = 0
    let dB = 0
    for (let i = 0; i < m; i += 1) {
        // Это производная функции стоимости параметра 'w'.
        // Она показывает, в каком направлении (положительный/отрицательный знак 'dW') и
        // на сколько (абсолютное значение 'dW') параметр 'w' должен быть изменен
        dW += (yTrain[i] - predictions[i]) * xTrain[i]
        // Это производная функции стоимости параметра 'b'.
        // Она показывает, в каком направлении (знак 'dB') и
        // на сколько (абсолютное значение 'dB') параметр 'b' должен быть изменен
        dB += yTrain[i] - predictions[i]
    }
    // Нас интересуют средняя дельта каждого параметра
    dW /= m
    dB /= m
    if (dW > 10) {
        dW = 10
    }
    return [dW, dB]
}

// Обучает модель.
// Это "учитель" нашего нейрончика:
// - он проводит некоторое время (epochs) с нашим глупым нейрончиком и пытается его чему-то научить,
// - он использует специальные "книги" (наборы данных xTrain и yTrain) для обучения,
// - он заставляет ребенка учиться усерднее (быстрее) с помощью параметра оценки обучения 'alpha'
// (чем сильнее стимул, тем быстрее модель учится, но если учитель будет давить слишком сильно
// у "ребенка" может случиться нервный срыв, и больше он не сможет учиться)
function trainModel(model, epochs, alpha, xTrain, yTrain) {
    // История обучения модели.
    // Она может содержать хорошие или плохие "оценки" (стоимость),
    // полученные в процессе обучения
    const costHistory = []

    // Перебираем эпохи
    for (let i = 0; i < epochs; i += 1) {
        // Прямое распространение для всех тренировочных примеров.
        // Сохраняем стоимость текущей итерации.
        // Это поможет анализировать обучение модели
        const [predictions, cost] = forwardPropagation(model, xTrain, yTrain)
        costHistory.push(cost)

        // Обратное распространение. Учимся на ошибках.
        // Эта функция возвращает небольшие модификации, которые нужно применить к параметрам 'w' и 'b',
        // чтобы сделать предсказания более точными
        const [dW, dB] = backwardPropagation(predictions, xTrain, yTrain)

        if (dW == null || dB == null || isNaN(dW)) {
            console.trace("Null")
            throw new Error("Null")
        }

        // Модифицируем параметры нейрончика для повышения точности его предсказаний
        nanoNeuron.w += alpha * dW
        nanoNeuron.b += alpha * dB
    }

    // Возвращаем историю обучения для анализа и визуализации
    return costHistory
}

// ===
// Создаем экземпляр модели.
// В данный момент нейрончику неизвестны значения параметров 'w' и 'b'.
// Устанавливаем их произвольно
const w = Math.random() // например -> 0.9492
const b = Math.random() // например -> 0.4570
const nanoNeuron = new NanoNeuron(w, b)

// Генерируем тренировочные и тестовые наборы данных
const [xTrain, yTrain, xTest, yTest] = generateDataSets()

// Обучаем модель небольшими шагами (0.0005) в течение 70000 эпох.
// Можете попробовать другие значения, они определены эмпирическим путем
const epochs = 70000
const alpha = 0.0005
const trainingCostHistory = trainModel(
    nanoNeuron,
    epochs,
    alpha,
    xTrain,
    yTrain,
)

// Проверим, как менялась стоимость в процессе обучения.
// Мы ожидаем, что стоимость после обучения будет значительно ниже, чем до него.
// Это будет означать, что наш нейрончик стал умнее. Но возможно и обратное
console.log('Стоимость до обучения:', trainingCostHistory[0]) // например -> 4694.3335043
console.log('Стоимость после обучения:', trainingCostHistory[epochs - 1]) // например -> 0.0000024

// Взглянем на параметры нейрончика, чтобы увидеть, чему он научился.
// Мы ожидаем, что значения параметров 'w' и 'b' модели будут близки к истинным значениям,
// которые используются в функции celsiusToFahrenheit() (w = 1.8 и b = 32)
console.log(
    'Параметры нейрончика:',
    JSON.stringify({ w: nanoNeuron.w, b: nanoNeuron.b }, null, 2),
) // например -> { w: 1.8, b: 31.99 }

// Оцениваем точность модели на тестовых данных, чтобы увидеть, насколько хорошо она обрабатывает неизвестные данные.
// Мы ожидаем, что стоимость тестовых предсказаний будет близкой к стоимости тренировочных предсказаний.
// Это будет означать, что нейрончик хорошо справляется как с тренировочными, так и с тестовыми данными
const [testPredictions, testCost] = forwardPropagation(nanoNeuron, xTest, yTest)
console.log('Стоимость тестовых предсказаний:', testCost) // например -> 0.0000023

// После того, как "ребенок" хорошо показал себя в "школе" в процессе обучения и хорошо справился с тестовыми данными,
// мы можем назвать его "умным" и задать ему парочку вопросов
const tempInCelsius = 70
const customPrediction = nanoNeuron.predict(tempInCelsius)
console.log(
    `Нейрончик "думает", что ${tempInCelsius}°C в градусах Фаренгейта:`,
    customPrediction,
) // -> 158.0002
console.log('Правильный ответ:', celsiusToFahrenheit(tempInCelsius))
